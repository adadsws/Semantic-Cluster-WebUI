"""
Step-0: Image Indexing
æ‰«æè¾“å…¥ç›®å½•ï¼Œç”Ÿæˆå›¾åƒç´¢å¼•æ–‡ä»¶ S0_image_index.json

ğŸ“… Last Updated: 2026-01-31
ğŸ“– Reference: docs/workflow-structure.md
"""

import json
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from PIL import Image
from tqdm import tqdm


class ImageIndexer:
    """
    å›¾åƒç´¢å¼•å™¨ - æ‰«æç›®å½•å¹¶ç”Ÿæˆç´¢å¼•
    """
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–ç´¢å¼•å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ•°æ®æºé…ç½®
        """
        self.config = config
        self.input_dir = Path(config['data']['input_directory'])
        self.supported_formats = config['data']['supported_formats']
        self.min_size_kb = config['data']['min_file_size_kb']
        self.max_size_mb = config['data']['max_file_size_mb']
        self.exclude_folders = config['data'].get('exclude_folders', '').split(',')
        self.exclude_folders = [f.strip() for f in self.exclude_folders if f.strip()]
    
    def _should_exclude_path(self, path: Path) -> bool:
        """
        æ£€æŸ¥è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤
        
        Args:
            path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            True if should exclude, False otherwise
        """
        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤æ–‡ä»¶å¤¹ä¸­
        for exclude_folder in self.exclude_folders:
            if exclude_folder in str(path):
                return True
        return False
    
    def _is_valid_image(self, image_path: Path) -> Tuple[bool, Optional[str]]:
        """
        æ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰æ•ˆ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            (is_valid, error_message)
        """
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        size_bytes = image_path.stat().st_size
        size_kb = size_bytes / 1024
        size_mb = size_kb / 1024
        
        # å¤§å°è¿‡æ»¤ï¼šmin_size_kb<=0 è¡¨ç¤ºä¸è®¾ä¸‹é™ï¼Œmax_size_mb<=0 è¡¨ç¤ºä¸è®¾ä¸Šé™
        if self.min_size_kb > 0 and size_kb < self.min_size_kb:
            return False, f"File too small: {size_kb:.2f} KB < {self.min_size_kb} KB"
        if self.max_size_mb > 0 and size_mb > self.max_size_mb:
            return False, f"File too large: {size_mb:.2f} MB > {self.max_size_mb} MB"
        
        # å°è¯•æ‰“å¼€å›¾åƒéªŒè¯
        try:
            with Image.open(image_path) as img:
                img.verify()  # éªŒè¯å›¾åƒå®Œæ•´æ€§
            return True, None
        except Exception as e:
            return False, f"Invalid image: {str(e)}"
    
    def _calculate_hash(self, image_path: Path) -> str:
        """
        è®¡ç®—å›¾åƒçš„SHA-256å“ˆå¸Œå€¼ï¼ˆç”¨äºå»é‡ï¼‰
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            SHA-256å“ˆå¸Œå€¼
        """
        sha256_hash = hashlib.sha256()
        with open(image_path, "rb") as f:
            # åˆ†å—è¯»å–ä»¥å¤„ç†å¤§æ–‡ä»¶
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    def scan_directory(self) -> Dict[str, dict]:
        """
        æ‰«æç›®å½•å¹¶ç”Ÿæˆç´¢å¼•
        
        Returns:
            å›¾åƒç´¢å¼•å­—å…¸ {image_id: {path, size, width, height, hash}}
        """
        if not self.input_dir.exists():
            raise FileNotFoundError(f"Input directory not found: {self.input_dir}")
        
        print(f"[Step-0] Scanning directory: {self.input_dir}")
        print(f"[Step-0] Supported formats: {', '.join(self.supported_formats)}")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in self.supported_formats:
            # æ”¯æŒå¤§å°å†™
            image_files.extend(self.input_dir.rglob(f"*.{ext}"))
            image_files.extend(self.input_dir.rglob(f"*.{ext.upper()}"))
        
        print(f"[Step-0] Found {len(image_files)} potential image files")
        
        # å»é‡ï¼ˆå¤„ç†å¤§å°å†™æ‰©å±•åé‡å¤ï¼‰
        image_files = list(set(image_files))
        print(f"[Step-0] After deduplication: {len(image_files)} files")
        
        # å¤„ç†æ¯ä¸ªå›¾åƒ
        index = {}
        valid_count = 0
        excluded_count = 0
        invalid_size_count = 0
        hash_dup_count = 0
        error_count = 0
        seen_hashes = {}
        
        for image_path in tqdm(image_files, desc="Indexing images"):
            # æ£€æŸ¥æ’é™¤è·¯å¾„
            if self._should_exclude_path(image_path):
                excluded_count += 1
                continue
            
            # éªŒè¯å›¾åƒ
            is_valid, error_msg = self._is_valid_image(image_path)
            if not is_valid:
                invalid_size_count += 1
                continue
            
            # è®¡ç®—å“ˆå¸Œå€¼
            try:
                file_hash = self._calculate_hash(image_path)
                
                # æ£€æŸ¥é‡å¤ï¼ˆå†…å®¹ç›¸åŒåªä¿ç•™ç¬¬ä¸€å¼ ï¼‰
                if file_hash in seen_hashes:
                    hash_dup_count += 1
                    continue
                
                seen_hashes[file_hash] = str(image_path)
                
                # è·å–å›¾åƒä¿¡æ¯
                with Image.open(image_path) as img:
                    width, height = img.size
                
                # ç”Ÿæˆå”¯ä¸€ID
                image_id = f"img_{valid_count:06d}"
                
                # æ·»åŠ åˆ°ç´¢å¼•
                index[image_id] = {
                    'path': str(image_path),
                    'filename': image_path.name,
                    'size_bytes': image_path.stat().st_size,
                    'width': width,
                    'height': height,
                    'hash': file_hash,
                    'extension': image_path.suffix.lower()
                }
                
                valid_count += 1
                
            except Exception as e:
                print(f"[Warning] Error processing {image_path}: {e}")
                error_count += 1
                continue
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ’é™¤/æ— æ•ˆ/é‡å¤/å¼‚å¸¸ äº’ä¸é‡å ï¼‰
        total_skipped = excluded_count + invalid_size_count + hash_dup_count + error_count
        print(f"\n[Step-0] Indexing complete:")
        print(f"  Valid images: {valid_count}")
        print(f"  Skipped: {total_skipped} (excluded: {excluded_count}, invalid/size: {invalid_size_count}, hash duplicates: {hash_dup_count}, errors: {error_count})")
        
        return index
    
    def save_index(self, index: Dict[str, dict], output_path: Path) -> None:
        """
        ä¿å­˜ç´¢å¼•åˆ°JSONæ–‡ä»¶
        
        Args:
            index: å›¾åƒç´¢å¼•
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ç´¢å¼•
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(index, f, indent=2, ensure_ascii=False)
        
        print(f"[Step-0] Index saved to: {output_path}")
        print(f"[Step-0] Total images: {len(index)}")
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_images': len(index),
            'total_size_mb': sum(img['size_bytes'] for img in index.values()) / (1024 * 1024),
            'avg_size_mb': sum(img['size_bytes'] for img in index.values()) / len(index) / (1024 * 1024) if index else 0,
            'formats': {},
            'total_pixels': sum(img['width'] * img['height'] for img in index.values()),
        }
        
        # ç»Ÿè®¡æ¯ç§æ ¼å¼çš„æ•°é‡
        for img in index.values():
            ext = img['extension']
            stats['formats'][ext] = stats['formats'].get(ext, 0) + 1
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_path = output_path.parent / "S0_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"[Step-0] Statistics saved to: {stats_path}")


def run_step0(config: dict, output_dir: Path) -> Path:
    """
    è¿è¡ŒStep-0: å›¾åƒç´¢å¼•
    
    Args:
        config: é…ç½®å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        ç´¢å¼•æ–‡ä»¶è·¯å¾„
    """
    print("=" * 60)
    print("Step-0: Image Indexing")
    print("=" * 60)

    input_dir = Path(config['data']['input_directory'])
    print(f"[Step-0] è¾“å…¥ç›®å½•: {input_dir}")
    min_kb = config['data'].get('min_file_size_kb', 0)
    max_mb = config['data'].get('max_file_size_mb', -1)
    if min_kb <= 0 and (max_mb is None or max_mb <= 0):
        print("[Step-0] ä¸è¿›è¡Œå¤§å°è¿‡æ»¤")
    else:
        print(f"[Step-0] å¤§å°è¿‡æ»¤: {min_kb} KB ~ {max_mb} MB" + (" (æ— ä¸Šé™)" if max_mb <= 0 else ""))
    if config['data'].get('exclude_folders'):
        print(f"[Step-0] æ’é™¤æ–‡ä»¶å¤¹: {config['data']['exclude_folders']}")

    # åˆ›å»ºç´¢å¼•å™¨
    indexer = ImageIndexer(config)

    # æ‰«æç›®å½•
    print(f"[Step-0] å¼€å§‹æ‰«æâ€¦")
    index = indexer.scan_directory()

    if not index:
        raise ValueError("No valid images found in input directory")

    # ä¿å­˜ç´¢å¼•
    output_path = output_dir / "S0_image_index.json"
    indexer.save_index(index, output_path)

    print("=" * 60)
    print(f"[Step-0] Complete! Indexed {len(index)} images -> {output_path.name}")
    print("=" * 60)
    
    return output_path


# ============================================
# Testing
# ============================================

if __name__ == "__main__":
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from utils import ConfigLoader
    
    print("Testing Step-0: Image Indexing...")
    
    # åŠ è½½é…ç½®
    loader = ConfigLoader()
    
    # è®¾ç½®test_picsä½œä¸ºè¾“å…¥
    test_pics_path = Path(__file__).parent.parent / "test_pics"
    loader.set("data.input_directory", str(test_pics_path))
    
    config = loader.to_dict()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent.parent / "data" / "output" / "test_run"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¿è¡ŒStep-0
    try:
        index_path = run_step0(config, output_dir)
        print(f"\n[SUCCESS] Index file: {index_path}")
        
        # è¯»å–å¹¶æ˜¾ç¤ºç´¢å¼•æ‘˜è¦
        with open(index_path, 'r', encoding='utf-8') as f:
            index = json.load(f)
        
        print(f"\nIndex Summary:")
        print(f"  Total images: {len(index)}")
        if index:
            first_key = list(index.keys())[0]
            print(f"  Sample entry: {first_key}")
            print(f"    Path: {index[first_key]['path']}")
            print(f"    Size: {index[first_key]['size_bytes'] / 1024:.2f} KB")
            print(f"    Dimensions: {index[first_key]['width']}x{index[first_key]['height']}")
        
    except Exception as e:
        print(f"\n[ERROR] {e}")
        import traceback
        traceback.print_exc()
