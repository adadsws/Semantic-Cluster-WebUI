"""
å•å›¾æµ‹è¯•ï¼šå¹¶è¡Œæè¿°ï¼ˆStep-4ï¼‰ä¸è¯­ä¹‰è’¸é¦ï¼ˆStep-5ï¼‰
ç”¨ä¸€å¼ å›¾è·‘å®Œ Step-0ï½Step-5ï¼ŒéªŒè¯ VLM æè¿°ä¸ç°‡æ ‡ç­¾è’¸é¦ã€‚

ä¸æ­£å¸¸æµç¨‹ä¸€è‡´ï¼šåŒä¸€å¥— Step-0ï½Step-5ã€åŒä¸€ configï¼ˆconfig.yamlï¼‰ï¼Œä»…è¦†ç›–å•å›¾å¿…éœ€é¡¹
ï¼ˆè¾“å…¥ç›®å½•ã€è®¾å¤‡ã€min_samples=1ã€top_k=1 ç­‰ï¼‰ï¼›model_sourceã€max_image_size ç­‰ç”¨ config é»˜è®¤ã€‚

ç”¨æ³•: åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ
  python scripts/test_one_image_caption.py
  python scripts/test_one_image_caption.py path/to/one.jpg   # æŒ‡å®šå›¾ç‰‡

ğŸ“… 2026-01-31
"""

import json
import shutil
import sys
from pathlib import Path

import pandas as pd

ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT))

# å°½æ—©æ£€æµ‹ GPUï¼Œä¾›åç»­é…ç½®ä½¿ç”¨
try:
    import torch
    USE_CUDA = torch.cuda.is_available()
    if USE_CUDA:
        DEVICE_STR = "cuda"
        _gpu_name = torch.cuda.get_device_name(0) if torch.cuda.device_count() else "GPU"
    else:
        DEVICE_STR = "cpu"
        _gpu_name = None
except Exception:
    USE_CUDA = False
    DEVICE_STR = "cpu"
    _gpu_name = None

from utils import ConfigLoader
from core.step0_indexing import run_step0
from core.step1_embedding import run_step1
from core.step2_clustering import run_step2
from core.step3_sampling import run_step3
from core.step4_caption import run_step4
from core.step5_label import run_step5


def main():
    # å•å›¾è¾“å…¥ç›®å½•
    one_image_dir = ROOT / "data" / "one_image_test" / "input"
    one_image_dir.mkdir(parents=True, exist_ok=True)

    # è‹¥å‘½ä»¤è¡ŒæŒ‡å®šäº†å›¾ç‰‡ï¼Œå¤åˆ¶è¿‡å»ï¼›å¦åˆ™ä» test_pics å–ç¬¬ä¸€å¼ 
    if len(sys.argv) >= 2:
        src = Path(sys.argv[1])
        if not src.is_absolute():
            src = ROOT / src
        if not src.exists():
            print(f"[ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {src}")
            sys.exit(1)
        # æ¸…ç©º input ååªæ”¾è¿™ä¸€å¼ 
        for f in one_image_dir.iterdir():
            f.unlink()
        dest = one_image_dir / src.name
        shutil.copy2(src, dest)
        print(f"[*] ä½¿ç”¨æŒ‡å®šå›¾ç‰‡: {src.name} -> {dest}")
    else:
        test_pics = ROOT / "test_pics"
        if not test_pics.exists():
            print(f"[ERROR] test_pics ä¸å­˜åœ¨: {test_pics}")
            sys.exit(1)
        exts = (".jpg", ".jpeg", ".png", ".webp", ".bmp", ".tiff")
        images = [f for f in test_pics.iterdir() if f.suffix.lower() in exts and f.is_file()]
        if not images:
            print(f"[ERROR] test_pics ä¸‹æ— å›¾ç‰‡")
            sys.exit(1)
        # æ¸…ç©ºååªæ”¾ä¸€å¼ 
        for f in one_image_dir.iterdir():
            f.unlink()
        src = images[0]
        dest = one_image_dir / src.name
        shutil.copy2(src, dest)
        print(f"[*] ä½¿ç”¨å•å›¾: {src.name} -> {one_image_dir / src.name}")

    # è¾“å‡ºç›®å½•
    from datetime import datetime
    session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = ROOT / "data" / "one_image_test" / f"out_{session_id}"
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"[*] è¾“å‡ºç›®å½•: {output_dir}")

    # å¼ºåˆ¶ä½¿ç”¨ GPUï¼ˆè‹¥å¯ç”¨ï¼‰
    if USE_CUDA:
        print(f"[*] ä½¿ç”¨è®¾å¤‡: {DEVICE_STR} ({_gpu_name})")
    else:
        print("[*] ä½¿ç”¨è®¾å¤‡: cpuï¼ˆæœªæ£€æµ‹åˆ° CUDAï¼Œè¯·ç¡®è®¤å·²å®‰è£… PyTorch GPU ç‰ˆ: pip install torch --index-url https://download.pytorch.org/whl/cu118ï¼‰")
    print()

    # é…ç½®ï¼šä¸æ­£å¸¸æµç¨‹åŒæº config.yamlï¼Œä»…è¦†ç›–å•å›¾æµ‹è¯•å¿…éœ€é¡¹ï¼›å…¶ä½™ï¼ˆmodel_sourceã€max_image_sizeã€model_scale ç­‰ï¼‰ç”¨ config é»˜è®¤
    loader = ConfigLoader()
    loader.set("data.input_directory", str(one_image_dir.resolve()))
    loader.set("embedding.device", DEVICE_STR)
    loader.set("embedding.backbone", "dinov2_vitl14")  # ä¸ UI ä¸€è‡´ï¼šprovider=dinov2 æ—¶ç”¨ vitl14
    loader.set("vlm.device", DEVICE_STR)
    loader.set("vlm.model_scale", "small")
    loader.set("vlm.caption_batch_size", 4)
    loader.set("clustering.backend", "sklearn")
    loader.set("clustering.min_samples", 1)
    loader.set("clustering.epsilon", 0.5)
    loader.set("postprocessing.caption_mode", "representative")
    loader.set("postprocessing.top_k_sampling", 1)
    config = loader.to_dict()

    try:
        # Step-0 ç´¢å¼•
        print("[Step-0] å›¾åƒç´¢å¼•ï¼ˆ1 å¼ ï¼‰â€¦")
        index_path = run_step0(config, output_dir)
        with open(index_path, "r", encoding="utf-8") as f:
            index = json.load(f)
        assert len(index) == 1, f"æœŸæœ› 1 å¼ å›¾ï¼Œå®é™… {len(index)}"
        print(f"  -> {list(index.keys())[0]}\n")

        # Step-1 åµŒå…¥
        print("[Step-1] ç‰¹å¾åµŒå…¥â€¦")
        run_step1(config, index_path, output_dir)
        print()

        # Step-2 èšç±»ï¼ˆ1 ç‚¹ â†’ 1 ç°‡ï¼‰
        print("[Step-2] èšç±»ï¼ˆ1 ç°‡ï¼‰â€¦")
        run_step2(
            config,
            output_dir / "S1_embeddings.npy",
            output_dir / "S1_image_ids.json",
            output_dir,
        )
        print()

        # Step-3 é‡‡æ ·ï¼ˆ1 ç°‡ 1 ä»£è¡¨ï¼‰
        print("[Step-3] å¤šç‚¹é‡‡æ ·â€¦")
        sampled_path = run_step3(
            config,
            output_dir / "S1_embeddings.npy",
            output_dir / "S1_image_ids.json",
            output_dir / "S2_clustering.csv",
            output_dir,
        )
        print()

        # Step-4 å¹¶è¡Œæè¿°ï¼ˆVLM æè¿°è¿™ä¸€å¼ å›¾ï¼‰
        print("[Step-4] å¹¶è¡Œæè¿°ï¼ˆVLM å•å›¾æè¿°ï¼‰â€¦")
        s4_path = run_step4(
            config,
            index_path,
            output_dir / "S2_clustering.csv",
            output_dir,
            mode="representative",
            sampled_path=sampled_path,
        )
        with open(s4_path, "r", encoding="utf-8") as f:
            captions = json.load(f)
        print("\n[Step-4] æè¿°ç»“æœ S4_captions.json:")
        for iid, cap in captions.items():
            preview = (cap or "").strip()[:200]
            print(f"  {iid}: {preview}..." if len((cap or "")) > 200 else f"  {iid}: {preview}")
        print()

        # Step-5 è¯­ä¹‰è’¸é¦ï¼ˆ1 ç°‡ â†’ 1 æ ‡ç­¾ï¼‰
        print("[Step-5] è¯­ä¹‰è’¸é¦â€¦")
        s5_path = run_step5(config, s4_path, sampled_path, output_dir)
        labels_df = pd.read_csv(s5_path)
        print("\n[Step-5] ç°‡æ ‡ç­¾ S5_cluster_labels.csv:")
        print(labels_df.to_string(index=False))
        print()

        print("=" * 60)
        print("  å•å›¾æµ‹è¯•å®Œæˆï¼šå¹¶è¡Œæè¿° + è¯­ä¹‰è’¸é¦ å·²è·‘é€š")
        print("=" * 60)
        print(f"  è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  S4: {s4_path.name}")
        print(f"  S5: {s5_path.name}")
    except Exception as e:
        print(f"\n[ERROR] {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
